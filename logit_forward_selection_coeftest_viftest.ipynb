{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from tqdm import tqdm_notebook\n",
    "import os, re, sys, gc, pickle, time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from plot_metric.functions import BinaryClassification\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from tqdm import tqdm_notebook\n",
    "import os, re, sys, gc, pickle, time\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,\\\n",
    "                                    KFold, train_test_split, cross_validate, ParameterGrid,\\\n",
    "                                    cross_validate, cross_val_predict, TimeSeriesSplit, StratifiedKFold\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin,  clone\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# пайплайн\n",
    "from sklearn.pipeline import Pipeline, make_union, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin,  clone\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# дамми-регрессор\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from itertools import combinations\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import roc_curve\n",
    "import shutil\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnHelperLogitSelector(BaseEstimator, TransformerMixin):\n",
    "    ''' Отбор признаков '''\n",
    "    def __init__(self, model, cv, scoring, show_progress):\n",
    "        self.model = model\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.show_progress = show_progress\n",
    "    def fit(self, X, y=None):\n",
    "        #####################################################################################################\n",
    "        def calc_vif(X): \n",
    "            _X = pd.DataFrame(X)\n",
    "            vif = pd.DataFrame()\n",
    "            vif[\"variables\"] = _X.columns\n",
    "            vif[\"VIF\"] = [variance_inflation_factor(_X.values, i) for i in tqdm_notebook(range(_X.shape[1]))]\n",
    "            return(vif)\n",
    "        ######################################################################################################\n",
    "        _X = X.copy()\n",
    "        cv_scores = []\n",
    "        for i in tqdm_notebook(range(_X.shape[1])):\n",
    "            try:\n",
    "                _X_curr = _X[:, i].toarray().reshape(-1,1)\n",
    "            except:\n",
    "                _X_curr = _X[:, i].reshape(-1,1)                \n",
    "            mean_cv_score = cross_val_score(self.model, _X_curr, y, cv =self.cv, scoring = self.scoring, n_jobs=-1).mean()            \n",
    "            cv_scores.append(mean_cv_score)\n",
    "            \n",
    "        order = np.argsort(cv_scores)[::-1]\n",
    "        to_drop_before, best_features, best_cv_score = [], [order[0]], -np.inf\n",
    "        for i in tqdm_notebook(order[1:]):\n",
    "            curr_features = best_features+[i]\n",
    "            _X_curr = _X[:, curr_features]\n",
    "            mean_cv_score = cross_val_score(self.model, _X_curr, y, cv =self.cv, scoring = self.scoring, n_jobs=-1).mean()\n",
    "            if mean_cv_score>best_cv_score:\n",
    "                sm_logit = sm.Logit(y, _X_curr).fit()\n",
    "                pVals = np.array(sm_logit.pvalues)\n",
    "                if np.all(pVals<=.05):                    \n",
    "                    best_cv_score = mean_cv_score\n",
    "                    best_features = curr_features\n",
    "                    if self.show_progress:\n",
    "                        print('new best score = {:.10f}'.format(best_cv_score))\n",
    "            else:\n",
    "                to_drop_before.append(i)\n",
    "        while True:\n",
    "            to_drop_after = []\n",
    "            for i in tqdm_notebook(to_drop_before):\n",
    "                curr_features = best_features+[i]\n",
    "                _X_curr = _X[:, curr_features]\n",
    "                mean_cv_score = cross_val_score(self.model, _X_curr, y, cv =self.cv, scoring = self.scoring, n_jobs=-1).mean()\n",
    "                if mean_cv_score>best_cv_score:\n",
    "                    sm_logit = sm.Logit(y, _X_curr).fit()\n",
    "                    pVals = np.array(sm_logit.pvalues)\n",
    "                    if np.all(pVals<=.05):\n",
    "                        vif = calc_vif(_X_curr)\n",
    "                        if (vif['VIF']<=10).all():\n",
    "                            best_cv_score = mean_cv_score\n",
    "                            best_features = curr_features\n",
    "                            if self.show_progress:\n",
    "                                print('new best score = {:.10f}'.format(best_cv_score))\n",
    "                else:\n",
    "                    to_drop_after.append(i)\n",
    "            if to_drop_before == to_drop_after:\n",
    "                break\n",
    "            else:\n",
    "                to_drop_before = to_drop_after  \n",
    "        self.best_features_ = best_features\n",
    "        self.best_score_ = best_cv_score\n",
    "    def transform(self, _X):\n",
    "        return _X[:, self.best_features_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.read_pickle('X_tr.pickle')\n",
    "X_te = pd.read_pickle('X_te.pickle')\n",
    "y_tr = pd.read_pickle('y_tr.pickle')\n",
    "y_te = pd.read_pickle('y_te.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 13\n",
    "logit = LogisticRegression(random_state= SEED)\n",
    "SKF = StratifiedKFold(5, shuffle = True, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = make_pipeline(MinMaxScaler(),\\\n",
    "                    SimpleImputer(strategy='constant', fill_value=-1),\\\n",
    "                    SklearnHelperLogitSelector(model=logit, cv=SKF, scoring='roc_auc', show_progress=True))\n",
    "ppl.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_tr = ppl.transform(X_tr)\n",
    "_x_te = ppl.transform(X_te)\n",
    "_y_tr = y_tr.values\n",
    "_y_te = y_te.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_gs = GridSearchCV(LogisticRegression(),\\\n",
    "                         param_grid = {'C':np.logspace(-3, 3, 500),\n",
    "                                        'random_state': [SEED],\\\n",
    "                                        'solver' : ['liblinear'],\\\n",
    "                                        'penalty':['l1','l2']},\\\n",
    "                        scoring ='roc_auc', cv = SKF, verbose = 1,n_jobs=-1)\n",
    "logit_gs.fit(_x_tr, _y_tr)\n",
    "GINI_best_cv = 100*((2 *logit_gs.best_score_)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.50784319223065"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GINI_best_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predprob_te = pd.DataFrame(logit_gs.best_estimator_.predict_proba(_x_te)[:,1], columns= ['predprob'])\n",
    "y_predprob_te['ucdb_id'] = y_te.index\n",
    "y_predprob_te = y_predprob_te[['ucdb_id', 'predprob']]\n",
    "y_predprob_te.to_excel('y3_predprob_te_v4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
