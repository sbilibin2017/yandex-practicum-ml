{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение для текстов\n",
    "\n",
    "## Постановка задачи: \n",
    "Построить модель классификации коммнетариев пользовавтелей на позитивные и негативные\n",
    "\n",
    "## Данные:\n",
    "\n",
    "|text|toxic|\n",
    "|---|---|\n",
    "|текст комментария|целевой признак|\n",
    "\n",
    "## Метрика качества: \n",
    "f1\n",
    "\n",
    "## Этапы работы:\n",
    "\n",
    "0. Импорт библиотек + Объявление констант\n",
    "\n",
    "1. Загрузка и подготовка данных\n",
    "\n",
    "    1.1. целевой признак\n",
    "    \n",
    "    1.2. подготовка текста сообщений (приводим к нижнему регистру, удаляем лишние пробелы, проводим токенизацию + лемматизацию, удаляем стоп-слова)\n",
    "    \n",
    "2. Обучение моделей\n",
    "\n",
    "    2.1. делим данные на тренировочну, отложенную, тестовую части\n",
    "    \n",
    "    2.2 получаем бейзлайн решение \n",
    "    \n",
    "    2.3. тестирование пайплайнов \n",
    "    \n",
    "    2.4. подбор гиперпараметров\n",
    "    \n",
    "## Выводы:\n",
    "* около 10% комментариев являются токсичными\n",
    "* модели в порядке убывания метрики качества: SupportVectorClassifier, Lightgbm, RandomForest, LogisticRegression, KNeighborsClassifier\n",
    "* быстрее всех валидировался SupportVectorClassifier, дольше всех- KNeighborsClassifier\n",
    "* lightgbm переобучился на тренировочный датасет\n",
    "* SupportVectorClassifier слабо зависит от гиперпараметров\n",
    "* результаты валидации\n",
    "\n",
    "|модель|f1(валидация)|f1(отложенная)|время обучения(сек)|\n",
    "|---|---|---|---|\n",
    "|SupportVectorClassifier|0.7638233030317889|0.7672023073753605|2|\n",
    "|LogisticRegression|0.7200374824206034|0.7250996015936255|3|\n",
    "|RandomForest|0.7475404652190069|0.7507282563462339|91|\n",
    "|Lightgbm|0.7369308873299057|0.7216404886561956|25|\n",
    "|KNeighbors|0.38758200880725563|0.40494092373791624|109|\n",
    "\n",
    "\n",
    "* финальный результат(SupportVectorClassifier, f1):\n",
    "\n",
    "|cv|hold|test|\n",
    "|---|---|---|\n",
    "|0.76412|0.76449|0.76562|\n",
    "\n",
    "## Общий вывод:\n",
    "В процесе выполнения работы была проведена стандартная подготовка текста, с помощью кросс-валидации протестированы различные модели и оптимизирована векторизация текста, лучшее значение f1 было достигнуто с помощью LinearSVC. Цель проекта - обучить модель классифицировать комментарии на позитивные и негативные достигнута."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack, vstack, csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk, re, string, gc, pickle\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV,\\\n",
    "                                    StratifiedKFold, ParameterGrid\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генератор случайных чисел\n",
    "SEED=13\n",
    "# доля тестовой части\n",
    "TEST_SIZE = .2\n",
    "# доля отложенной части\n",
    "HOLD_SIZE = .1\n",
    "# валидация\n",
    "SKF = StratifiedKFold(3, shuffle = True, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # серверный путь\n",
    "    df= pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    # локальный путь\n",
    "    df= pd.read_csv('datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% токичных комментариев равен 10%\n"
     ]
    }
   ],
   "source": [
    "print('% токичных комментариев равен {:.0%}'.format(df['toxic'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. подготовка текста\n",
    "* приводим к нижнему регистру\n",
    "* удаляем лишние пробелы\n",
    "* проводим токенизацию + лемматизацию\n",
    "* удаляем специальные символы\n",
    "* удаляем стоп-слова(с помощью параметра в векторайзере tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebf6b74f3104a5288a572cbc9865f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# лемматайзер\n",
    "lemma_function = WordNetLemmatizer()\n",
    "\n",
    "# словарь с тегами частей речи\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "# проходим по сообщениям\n",
    "for idx, text in tqdm_notebook(df['text'].items(), total = len(df)):    \n",
    "    \n",
    "    # приводим к нижнему регистру, удаляем пунктуацию\n",
    "    txt = text.lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # удаляем лишние пробелы\n",
    "    txt_stripped = ' '.join([element for element in txt.strip().split(' ') if element !=''])\n",
    "    \n",
    "    # токенизация + лемматизация\n",
    "    tokens = word_tokenize(txt_stripped)    \n",
    "    L_txt_lemmas = []\n",
    "    for token, tag in pos_tag(tokens):\n",
    "        lemma = lemma_function.lemmatize(token, tag_map[tag[0]])\n",
    "        lemma2 = re.sub('[^A-Za-z0-9]+', '', lemma)\n",
    "        if lemma2 != ' ':\n",
    "            L_txt_lemmas.append(lemma2)\n",
    "    txt_lemmas = ' '.join(L_txt_lemmas)\n",
    "    \n",
    "    # сохраняем обработанную строку\n",
    "    df.loc[idx, 'text_preprocessed'] = txt_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('df_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25680</th>\n",
       "      <td>(incorrect, moronic allegations of)</td>\n",
       "      <td>1</td>\n",
       "      <td>incorrect moronic allegation of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74202</th>\n",
       "      <td>As the previous article lead already used, dig...</td>\n",
       "      <td>0</td>\n",
       "      <td>a the previous article lead already use digita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87912</th>\n",
       "      <td>▲ to ? \\n\\n...character encoding issues. Oops....</td>\n",
       "      <td>0</td>\n",
       "      <td>to character encode issue oops fix now natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130308</th>\n",
       "      <td>Yes. I know that was what Mikka did. And you k...</td>\n",
       "      <td>0</td>\n",
       "      <td>yes i know that be what mikka do and you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147189</th>\n",
       "      <td>Son of a bitchSon of a bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>son of a bitchson of a bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39914</th>\n",
       "      <td>\"\\n\\n Villavar Theory \\n\\nI strongly suspect t...</td>\n",
       "      <td>0</td>\n",
       "      <td>villavar theory i strongly suspect the reliabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112683</th>\n",
       "      <td>Deleting entire paragraphs\\n\\nAnonymous users ...</td>\n",
       "      <td>0</td>\n",
       "      <td>delete entire paragraph anonymous user and any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59468</th>\n",
       "      <td>\"\\n\\nThe trouble with Mahler analysis is that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>the trouble with mahler analysis be that there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31527</th>\n",
       "      <td>Stop reverting edits because you don't like th...</td>\n",
       "      <td>0</td>\n",
       "      <td>stop revert edits because you dont like them i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101319</th>\n",
       "      <td>can somebody check my sandbox? I just want to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>can somebody check my sandbox i just want to c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "25680                 (incorrect, moronic allegations of)      1   \n",
       "74202   As the previous article lead already used, dig...      0   \n",
       "87912   ▲ to ? \\n\\n...character encoding issues. Oops....      0   \n",
       "130308  Yes. I know that was what Mikka did. And you k...      0   \n",
       "147189                       Son of a bitchSon of a bitch      1   \n",
       "39914   \"\\n\\n Villavar Theory \\n\\nI strongly suspect t...      0   \n",
       "112683  Deleting entire paragraphs\\n\\nAnonymous users ...      0   \n",
       "59468   \"\\n\\nThe trouble with Mahler analysis is that ...      0   \n",
       "31527   Stop reverting edits because you don't like th...      0   \n",
       "101319  can somebody check my sandbox? I just want to ...      0   \n",
       "\n",
       "                                        text_preprocessed  \n",
       "25680                     incorrect moronic allegation of  \n",
       "74202   a the previous article lead already use digita...  \n",
       "87912    to character encode issue oops fix now natura...  \n",
       "130308  yes i know that be what mikka do and you know ...  \n",
       "147189                       son of a bitchson of a bitch  \n",
       "39914   villavar theory i strongly suspect the reliabi...  \n",
       "112683  delete entire paragraph anonymous user and any...  \n",
       "59468   the trouble with mahler analysis be that there...  \n",
       "31527   stop revert edits because you dont like them i...  \n",
       "101319  can somebody check my sandbox i just want to c...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "* около 10% комментариев являются токсичными\n",
    "* произведена предобработка комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. делим данные на тренировочну, отложенную, тестовую части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки, целевой признак\n",
    "FEATURES, TARGET = df['text_preprocessed'].values.astype('U'), df['toxic'].values\n",
    "\n",
    "# тренировочная, тестовая выборки\n",
    "features_tr, features_te, target_tr, target_te = train_test_split(FEATURES,TARGET, test_size=TEST_SIZE,\\\n",
    "                                                                  shuffle = True, random_state = SEED)\n",
    "# разделитель для отложенной выборки\n",
    "idx_split = int(round(len(features_tr)*(1-HOLD_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. дамми-модель(бейзлайн)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d67dfcf3ce941ed9e189cc0970631d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "L_cv_results = []\n",
    "for strategy in tqdm_notebook(('stratified', 'most_frequent', 'prior', 'uniform')):\n",
    "    dummy_clf = DummyClassifier(strategy)\n",
    "    L_cv_results.append(('dummy', strategy,\\\n",
    "                         cross_val_score(dummy_clf,features_tr, target_tr, cv = SKF, scoring = 'f1').mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummy</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.169316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dummy</td>\n",
       "      <td>stratified</td>\n",
       "      <td>0.104153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dummy</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummy</td>\n",
       "      <td>prior</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model       features  cv_score\n",
       "0  dummy        uniform  0.169316\n",
       "1  dummy     stratified  0.104153\n",
       "2  dummy  most_frequent  0.000000\n",
       "3  dummy          prior  0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(L_cv_results, columns = ['model', 'features', 'cv_score'])\\\n",
    "  .sort_values('cv_score', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del L_cv_results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "* получены базовые значения метрик\n",
    "* лучше всех сработало равномерное предсказание "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. пайплайны (запускать необязательно. результаты сохранил)\n",
    "* использовались модели разной природы\n",
    "* признаки: tfidf. max_features(топ n), ngram_range(энграммы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модели\n",
    "models_d = {'svc':LinearSVC(random_state = SEED),\\\n",
    "            'logit': LogisticRegression(random_state = SEED),\\\n",
    "            'rf':RandomForestClassifier(random_state = SEED, n_jobs = -1),\\\n",
    "            'lgb' : LGBMClassifier(random_state = SEED, n_jobs = -1),\n",
    "            'knn':KNeighborsClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пайплайн №1\n",
    "ppl = Pipeline([('vectorizer', TfidfVectorizer(stop_words = 'english', max_features = 10000))]) \n",
    "ppl.fit(features_tr, target_tr)\n",
    "\n",
    "# признаки\n",
    "features1_tr = ppl.transform(features_tr)\n",
    "features1_te = ppl.transform(features_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd56368db0de43ca9130968875e84da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "L1_scores = []\n",
    "# проходим по моделям\n",
    "for model_name, model in tqdm_notebook(models_d.items()):\n",
    "    \n",
    "    # валидация\n",
    "    start = time.time()\n",
    "    mean_cv_score = cross_val_score(model,\\\n",
    "                                    features1_tr[:idx_split], target_tr[:idx_split],\\\n",
    "                                    cv = SKF, scoring = 'f1', n_jobs = -1).mean()\n",
    "    end = time.time()\n",
    "    \n",
    "    # отложенная\n",
    "    model.fit(features1_tr[:idx_split], target_tr[:idx_split])\n",
    "    holdout_score = f1_score(target_tr[idx_split:], model.predict(features1_tr[idx_split:]))\n",
    "    \n",
    "    L1_scores.append((model_name, mean_cv_score, holdout_score, round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_scores_c = [('svc', 0.7638233030317889, 0.7672023073753605, 3),\n",
    " ('logit', 0.7200374824206034, 0.7250996015936255, 3),\n",
    " ('rf', 0.7475404652190069, 0.7507282563462339, 90),\n",
    " ('lgb', 0.7369308873299057, 0.7216404886561956, 22),\n",
    " ('knn', 0.38758200880725563, 0.40494092373791624, 99)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    cvAB = pd.DataFrame(L1_scores, columns = ['model', 'cv_score', 'holdout_score', 'duration'])\\\n",
    "             .sort_values('cv_score', ascending = False)\\\n",
    "             .set_index('model')\n",
    "except:\n",
    "    cvAB = pd.DataFrame(L1_scores_c, columns = ['model', 'cv_score', 'holdout_score', 'duration'])\\\n",
    "             .sort_values('cv_score', ascending = False)\\\n",
    "             .set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout_score</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.763823</td>\n",
       "      <td>0.767202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.747540</td>\n",
       "      <td>0.750728</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb</th>\n",
       "      <td>0.736931</td>\n",
       "      <td>0.721640</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit</th>\n",
       "      <td>0.720037</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.387582</td>\n",
       "      <td>0.404941</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cv_score  holdout_score  duration\n",
       "model                                   \n",
       "svc    0.763823       0.767202         3\n",
       "rf     0.747540       0.750728        90\n",
       "lgb    0.736931       0.721640        22\n",
       "logit  0.720037       0.725100         3\n",
       "knn    0.387582       0.404941        99"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "* модели в порядке убывания метрики качества: SupportVectorClassifier, Lightgbm, RandomForest, LogisticRegression, KNeighborsClassifier\n",
    "* быстрее всех валидировался SupportVectorClassifier, дольше всех- KNeighborsClassifier\n",
    "* lightgbm переобучился на тренировочный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491b65df4ad24f949886d03be9bf96fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eed63853084cdbbe7d980a3a111e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6cc34d4e1042ec96deb1fa63e43532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L2_scores = []\n",
    "\n",
    "# перебираем гиперпараметры tfidf\n",
    "for ngram_range in tqdm_notebook(((1, 1), (1, 2))):\n",
    "    for max_features in tqdm_notebook([10**i for i in range(1, 6)]):\n",
    "        \n",
    "        # пайплайн №2\n",
    "        ppl2 = Pipeline([('vectorizer', TfidfVectorizer(stop_words = 'english',\\\n",
    "                                                        max_features = max_features,\\\n",
    "                                                        ngram_range=ngram_range))]) \n",
    "        ppl2.fit(features_tr, target_tr)\n",
    "\n",
    "        # признаки №2\n",
    "        features2_tr = ppl2.transform(features_tr)\n",
    "        features2_te = ppl2.transform(features_te)\n",
    "            \n",
    "        mean_cv_score = cross_val_score(models_d['svc'],\\\n",
    "                                        features2_tr[:idx_split], target_tr[:idx_split],\\\n",
    "                                        cv = SKF, scoring = 'f1', n_jobs = -1).mean()\n",
    "        L2_scores.append((ngram_range, max_features, mean_cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:yellow;color:black\">сохраненные результаты</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_scores_с = [((1, 1), 10, 0.0),\n",
    " ((1, 1), 100, 0.3430036273771883),\n",
    " ((1, 1), 1000, 0.7001445657516144),\n",
    " ((1, 1), 10000, 0.7638233030317889),\n",
    " ((1, 1), 100000, 0.7620288765035749),\n",
    " ((1, 2), 10, 0.0),\n",
    " ((1, 2), 100, 0.3427699161249897),\n",
    " ((1, 2), 1000, 0.6898170821386255),\n",
    " ((1, 2), 10000, 0.7551298004899131),\n",
    " ((1, 2), 100000, 0.7581537014948553)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    cvAB2 = pd.DataFrame(L2_scores, columns = ['ngram_range', 'max_features', 'mean_cv_score'])\\\n",
    "             .sort_values('mean_cv_score', ascending = False).reset_index(drop = True)             \n",
    "except:\n",
    "    cvAB2 = pd.DataFrame(L2_scores_с, columns = ['ngram_range', 'max_features', 'mean_cv_score'])\\\n",
    "             .sort_values('mean_cv_score', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>max_features</th>\n",
       "      <th>mean_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.763823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.762029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.758154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.755130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.700145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.689817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.343004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.342770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ngram_range  max_features  mean_cv_score\n",
       "0      (1, 1)         10000       0.763823\n",
       "1      (1, 1)        100000       0.762029\n",
       "2      (1, 2)        100000       0.758154\n",
       "3      (1, 2)         10000       0.755130\n",
       "4      (1, 1)          1000       0.700145\n",
       "5      (1, 2)          1000       0.689817\n",
       "6      (1, 1)           100       0.343004\n",
       "7      (1, 2)           100       0.342770\n",
       "8      (1, 1)            10       0.000000\n",
       "9      (1, 2)            10       0.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvAB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3addd70f7b64e8f8981318d8023d48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_score2 = cvAB2['mean_cv_score'].max()\n",
    "for max_features in tqdm_notebook(np.arange(5000, 100000, 10000)):\n",
    "    \n",
    "    # пайплайн №3\n",
    "    ppl3 = Pipeline([('vectorizer', TfidfVectorizer(stop_words = 'english',\\\n",
    "                                                    max_features = max_features,\\\n",
    "                                                    ngram_range=(1, 1)))]) \n",
    "    ppl3.fit(features_tr, target_tr)\n",
    "\n",
    "    # признаки №3\n",
    "    features3_tr = ppl3.transform(features_tr)\n",
    "    features3_te = ppl3.transform(features_te)\n",
    "    \n",
    "    mean_cv_score = cross_val_score(models_d['svc'],\\\n",
    "                                    features3_tr[:idx_split], target_tr[:idx_split],\\\n",
    "                                    cv = SKF, scoring = 'f1', n_jobs = -1).mean()\n",
    "    if mean_cv_score>best_score2:\n",
    "        best_score2 = mean_cv_score\n",
    "        best_max_features = max_features     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074cfe8ac3fb4c35b453d4560709cc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 10\n",
    "for i in tqdm_notebook(range(n_iterations)):\n",
    "    np.random.RandomState(i)\n",
    "    max_features = np.random.choice(np.arange(best_max_features-5000,best_max_features+5000))\n",
    "    \n",
    "    # пайплайн №4\n",
    "    ppl4 = Pipeline([('vectorizer', TfidfVectorizer(stop_words = 'english',\\\n",
    "                                                    max_features = max_features,\\\n",
    "                                                    ngram_range=(1, 1)))]) \n",
    "    ppl4.fit(features_tr, target_tr)\n",
    "\n",
    "    # признаки №4\n",
    "    features4_tr = ppl4.transform(features_tr)\n",
    "    features4_te = ppl4.transform(features_te)\n",
    "    \n",
    "    mean_cv_score = cross_val_score(models_d['svc'],\\\n",
    "                                    features4_tr[:idx_split], target_tr[:idx_split],\\\n",
    "                                    cv = SKF, scoring = 'f1', n_jobs = -1).mean()\n",
    "    if mean_cv_score>best_score2:\n",
    "        best_score2 = mean_cv_score\n",
    "        best_features_tr = features4_tr\n",
    "        best_features_te = features4_te\n",
    "    else:\n",
    "        best_features_tr = features3_tr\n",
    "        best_features_te = features3_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    1.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    8.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 cv (best) = 0.76412\n",
      "f1 hold (best) = 0.76449\n",
      "f1 test (best) = 0.76562\n"
     ]
    }
   ],
   "source": [
    "pg = {'C': [.1, 1, 5, 10, 100], 'penalty':['l1', 'l2', None], 'random_state':[SEED]}\n",
    "gs = GridSearchCV(models_d['svc'], param_grid = pg, cv =  SKF, scoring = 'f1', n_jobs=-1, verbose = 1)\n",
    "gs.fit(best_features_tr[:idx_split], target_tr[:idx_split])\n",
    "\n",
    "print('f1 cv (best) = {:.5f}'.format(gs.best_score_))\n",
    "print('f1 hold (best) = {:.5f}'.format(f1_score(target_tr[idx_split:],\\\n",
    "                                                gs.best_estimator_.predict(best_features_tr[idx_split:]))))\n",
    "print('f1 test (best) = {:.5f}'.format(f1_score(target_te,\\\n",
    "                                                gs.best_estimator_.predict(best_features_te))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "* linearSVC слабо зависит от гиперпараметров"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
