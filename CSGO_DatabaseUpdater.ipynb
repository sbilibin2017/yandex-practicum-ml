{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Класс для преобразования запией из парсера в таблицы из БД\n",
    "\n",
    "## пайплайн:\n",
    "* 1. выгрузка логов с сервера\n",
    "* 2. трансформация логов в таблицы из БД\n",
    "* 3. добавление записей (трансформированные логи) в БД\n",
    "\n",
    "## схема БД:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, json, os\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformerCSGO():\n",
    "    \n",
    "    def __init__(self, path_to_log, engine):\n",
    "        self.path_to_log = path_to_log \n",
    "        self.engine = engine \n",
    "    def transform_logs(self):\n",
    "        L_rows = []\n",
    "        with open(PATH_TO_LOG, 'r') as f:\n",
    "            json_log = json.load(f)\n",
    "            try:\n",
    "                for log in tqdm_notebook(json_log):\n",
    "                    df_row = pd.json_normalize(log)\n",
    "                    L_rows.append(df_row)\n",
    "            except:\n",
    "                pass\n",
    "        df = pd.concat(L_rows).reset_index(drop = True)\n",
    "        cs = []\n",
    "        for col in df.columns:\n",
    "            for c in col.split('.'):\n",
    "                if (c =='id') | ('_id' in c):\n",
    "                    cs.append(col)\n",
    "        idx_columns = list(set(cs))\n",
    "        df = df[~df[idx_columns].isna().any(1)]\n",
    "        self.df = df[df.columns[~df.isna().all()]]\n",
    "        return self    \n",
    "    \n",
    "    def get_tables(self):\n",
    "        \n",
    "        ##################################################################################################################\n",
    "        def _get_league_dict(subdf):\n",
    "            league_ser = pd.concat([subdf['match.league_id'].drop_duplicates(),\n",
    "                                        subdf['match.league.name'].drop_duplicates(),\n",
    "                                        subdf['match.league.modified_at'].drop_duplicates(),\n",
    "                                        subdf['match.league.slug'].drop_duplicates()])\n",
    "            try:\n",
    "                league_ser.index = ['id', 'name', 'modified_at', 'slug']\n",
    "                league_d = league_ser.to_dict()\n",
    "            except:\n",
    "                league_d = None\n",
    "            return league_d\n",
    "\n",
    "        def _get_serie_dict(subdf):\n",
    "            serie_ser = pd.concat([subdf['match.serie_id'].drop_duplicates(),\n",
    "                                       subdf['match.league_id'].drop_duplicates(),\n",
    "                                       subdf['match.serie.name'].drop_duplicates(),\n",
    "                                       subdf['match.serie.full_name'].drop_duplicates(),\n",
    "                                       subdf['match.serie.season'].drop_duplicates(),\n",
    "                                       subdf['match.serie.begin_at'].drop_duplicates(),\n",
    "                                       subdf['match.serie.end_at'].drop_duplicates(),\n",
    "                                       subdf['match.serie.modified_at'].drop_duplicates(),\n",
    "                                       subdf['match.serie.tier'].drop_duplicates()])\n",
    "            try:\n",
    "                serie_ser.index = ['id', 'league_id', 'name', 'full_name', 'season', 'begin_at', 'end_at', 'modified_at', 'tier']\n",
    "                serie_d = serie_ser.to_dict()\n",
    "            except:\n",
    "                serie_d = None  \n",
    "            return serie_d\n",
    "\n",
    "        def _get_tournament_dict(subdf):\n",
    "            tournament_ser = pd.concat([subdf['match.tournament.id'].drop_duplicates(),\n",
    "                                       subdf['match.serie.id'].drop_duplicates(),\n",
    "                                       subdf['match.tournament.name'].drop_duplicates(),\n",
    "                                       subdf['match.tournament.begin_at'].drop_duplicates(),\n",
    "                                       subdf['match.tournament.end_at'].drop_duplicates(),\n",
    "                                       subdf['match.tournament.winner_id'].drop_duplicates(),\n",
    "                                       subdf['match.tournament.prizepool'].drop_duplicates(),\n",
    "                                       subdf['match.tournament.modified_at'].drop_duplicates()])\n",
    "            try:\n",
    "                tournament_ser.index = ['id', 'serie_id', 'name', 'begin_at', 'end_at', 'winner_id', 'prizepool', 'modified_at']\n",
    "                tournament_d = tournament_ser.to_dict()\n",
    "            except:\n",
    "                tournament_d = None  \n",
    "            return tournament_d\n",
    "\n",
    "        def _get_match_dict(subdf):\n",
    "            L_row_matches = []\n",
    "            for _id, _subdf2 in subdf.groupby('id'):\n",
    "                match_ser = pd.concat([_subdf2['match_id'].drop_duplicates(),\n",
    "                                   _subdf2['match.tournament.id'].drop_duplicates(),\n",
    "                                   _subdf2['map.id'].drop_duplicates(),\n",
    "                                   _subdf2['match.winner_id'].drop_duplicates(),\n",
    "                                   _subdf2['match.begin_at'].drop_duplicates(),\n",
    "                                   _subdf2['match.end_at'].drop_duplicates(),\n",
    "                                   _subdf2['length'].drop_duplicates(),\n",
    "                                   _subdf2['position'].drop_duplicates(),\n",
    "                                   _subdf2['status'].drop_duplicates()])\n",
    "                try:\n",
    "                    match_ser.index = ['id', 'tournament_id', 'map_id', 'winner_id',\\\n",
    "                                           'begin_at', 'end_at', 'length', 'position', 'status']\n",
    "                    match_d = match_ser.to_dict()\n",
    "                except:\n",
    "                    match_d = None  \n",
    "                L_row_matches.append(match_d)\n",
    "            return L_row_matches\n",
    "\n",
    "        def _get_game_dict(subdf):\n",
    "            L_row_games = []\n",
    "            for idx in subdf['match.games'].astype(str).drop_duplicates().index:\n",
    "                row_df = subdf.loc[idx]\n",
    "                try:\n",
    "                    for game in row_df['match.games']:\n",
    "                        _subdf = subdf[subdf['begin_at'] == game['begin_at']]\n",
    "                        game_ser = _subdf['match_id'].drop_duplicates()\n",
    "                        game_ser = pd.concat([pd.Series(game['id'], index = game_ser.index),\n",
    "                                                  game_ser])\n",
    "                        game_ser.index = ['id', 'match_id']\n",
    "\n",
    "                        for i, rounds_score in enumerate(_subdf['rounds_score'].iloc[0]):\n",
    "                            game_ser[f'team{i+1}_id'] = rounds_score['team_id']\n",
    "                            game_ser[f'score{i+1}'] = rounds_score['score']\n",
    "                        L_row_games.append(game_ser.to_dict())\n",
    "                except:\n",
    "                    pass\n",
    "            return L_row_games\n",
    "\n",
    "        def _get_round_dict(subdf):\n",
    "            L_row_rounds = []\n",
    "            for idx in subdf['match.games'].astype(str).drop_duplicates().index:\n",
    "                row_df = subdf.loc[idx]\n",
    "                try:\n",
    "                    for game in row_df['match.games']:                \n",
    "                        _subdf = subdf[subdf['begin_at'] == game['begin_at']]\n",
    "                        _df_rounds = pd.DataFrame(_subdf['rounds'].iloc[0])\n",
    "                        _df_rounds['game_id'] = game['id']\n",
    "                        _df_rounds = _df_rounds.rename(columns = {'ct':'ct_id', 'terrorists':'t_id'})                \n",
    "                        L_row_rounds.append(_df_rounds)\n",
    "                except:\n",
    "                    pass\n",
    "            return L_row_rounds\n",
    "\n",
    "        def _get_team_dict(subdf):\n",
    "            L_teams =[]\n",
    "            for _d in subdf['teams'].iloc[0]:\n",
    "                L_teams.append({'id':_d['id'],\\\n",
    "                                    'modified_at':_d['modified_at'],\\\n",
    "                                    'name':_d['name'],\\\n",
    "                                    'location':_d['location']})\n",
    "            return L_teams\n",
    "\n",
    "        def _get_player_dict(subdf):\n",
    "            L_d_players = []    \n",
    "            for idx in subdf['players'].astype(str).drop_duplicates().index:\n",
    "                _s = subdf.loc[idx]\n",
    "                for player in _s['players']:    \n",
    "                    _d = player['player']\n",
    "                    _d['team_id'] = player['team']['id']\n",
    "\n",
    "                    d_player = {'id':_d['id'],'name':_d['name'], 'first_name':_d['first_name'],\\\n",
    "                                    'last_name':_d['last_name'], 'birthday':_d['birthday'],\\\n",
    "                                    'hometown':_d['hometown'], 'nationality':_d['nationality']}\n",
    "                    L_d_players.append(d_player)\n",
    "            return L_d_players\n",
    "\n",
    "        def _get_stat_dict(subdf):\n",
    "            L_d_players_stat = []\n",
    "            _subdf = subdf.drop_duplicates('id')\n",
    "            for i in _subdf.index:\n",
    "                _row = _subdf.loc[i]\n",
    "                for game in _row['match.games']:\n",
    "                    if _row['begin_at'] == game['begin_at']:\n",
    "                        for _i, player in enumerate(_row['players']):                \n",
    "                            d_player_stat = {'player_number':_i, 'game_id':game['id'], 'player_id':player['player']['id'],\\\n",
    "                                                 'adr':player['adr'], 'assists':player['assists'],\\\n",
    "                                                 'kills':player['kills'], 'deaths':player['deaths'],\\\n",
    "                                                 'headshots':player['headshots'], 'flash_assists':player['flash_assists'],\\\n",
    "                                                 'k_d_diff':player['k_d_diff'], 'kast':player['kast'],\\\n",
    "                                                 'rating':player['rating']}\n",
    "                            L_d_players_stat.append(d_player_stat)\n",
    "            return L_d_players_stat\n",
    "\n",
    "        def _get_map_dict(subdf):\n",
    "            d_map = dict(zip(subdf['map.id'], subdf['map.name']))\n",
    "            return d_map\n",
    "\n",
    "        def _convert_types(df):\n",
    "            L = []\n",
    "            for col in df.columns:\n",
    "                ser = df[col]\n",
    "                try:\n",
    "                    ser_dt = ser.astype('datetime64')\n",
    "                    L.append(ser_dt)\n",
    "                except:\n",
    "                    try:\n",
    "                        ser_int = ser.astype(int)\n",
    "                        _ser = ser\n",
    "                        if (ser_int == _ser).all():\n",
    "                            L.append(ser_int)                \n",
    "                    except:\n",
    "                        try:\n",
    "                            ser_float = ser.astype(float)\n",
    "                            L.append(ser_float) \n",
    "                        except:\n",
    "                            L.append(ser)  \n",
    "            return pd.concat(L, 1)          \n",
    "        ##################################################################################################################\n",
    "                \n",
    "        df = self.df        \n",
    "        DD = defaultdict(list)\n",
    "        for match_id, subdf in tqdm_notebook(df.groupby('match_id')):\n",
    "\n",
    "\n",
    "            try:\n",
    "                DD['Maps'].append(_get_map_dict(subdf))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                DD['Teams'].extend(_get_team_dict(subdf))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                DD['Players'].extend(_get_player_dict(subdf))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                DD['Leagues'].append(_get_league_dict(subdf))    \n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                DD['Series'].append(_get_serie_dict(subdf))    \n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                DD['Tournaments'].append(_get_tournament_dict(subdf))    \n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                DD['Matches'].extend(_get_match_dict(subdf))    \n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                DD['Games'].extend(_get_game_dict(subdf))    \n",
    "            except:\n",
    "                pass            \n",
    "            try:\n",
    "                DD['Rounds'].append(_get_round_dict(subdf))    \n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                DD['Stats'].extend(_get_stat_dict(subdf))    \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        DD2 = {}\n",
    "        for k in ['Teams', 'Players', 'Leagues', 'Series', 'Tournaments', 'Matches', 'Games']:\n",
    "            try:\n",
    "                DD2[k] = _convert_types(pd.DataFrame.from_records(DD[k])\\\n",
    "                                            .drop_duplicates(subset = ['id'])\\\n",
    "                                            .reset_index(drop = True))\n",
    "            except:                \n",
    "                DD2[k] = _convert_types(pd.concat(DD[k])\\\n",
    "                                            .drop_duplicates(subset = ['id'])\\\n",
    "                                            .reset_index(drop = True))\n",
    "        l_dfs= []\n",
    "        for dfs in DD['Rounds']:\n",
    "            for df in dfs:\n",
    "                l_dfs.append(df)\n",
    "        DD2['Rounds'] = _convert_types(pd.concat(l_dfs)).reset_index(drop = True)   \n",
    "        DD2['Stats'] = _convert_types(pd.DataFrame.from_records(DD['Stats'])).reset_index(drop = True)  \n",
    "         \n",
    "\n",
    "        d_map = {}\n",
    "        for _d in DD['Maps']:\n",
    "            for k, v in _d.items():\n",
    "                if k not in list(d_map.keys()):\n",
    "                    d_map[k] = v    \n",
    "        DD2['Maps'] = _convert_types(pd.Series(d_map).to_frame('name')\\\n",
    "                                     .reset_index().rename(columns = {'index':'id'}))\\\n",
    "                                     .drop_duplicates(subset = ['id']).reset_index(drop = True)     \n",
    "        self.d_tables=DD2\n",
    "        return DD2  \n",
    "    \n",
    "    def load_tables_to_database(self):\n",
    "        \n",
    "        df_Players =self.d_tables['Players']\n",
    "        df_Players.to_sql('Players', con=connection, index=False, if_exists='append')\n",
    "\n",
    "        df_Teams =self.d_tables['Teams']\n",
    "        df_Teams.to_sql('Teams', con=connection, index=False, if_exists='append')\n",
    "        Teams_touse= df_Teams['id'].unique()\n",
    "\n",
    "        df_Leagues =self.d_tables['Leagues']\n",
    "        df_Leagues.to_sql('Leagues', con=connection, index=False, if_exists='append')\n",
    "\n",
    "        df_Series =self.d_tables['Series']\n",
    "        df_Series.to_sql('Series', con=connection, index=False, if_exists='append')\n",
    "\n",
    "        df_tournaments = self.d_tables['Tournaments']\n",
    "        Tournaments_touse = df_tournaments['id'].unique()\n",
    "        df_tournaments= df_tournaments[df_tournaments['winner_id'].isin(Teams_touse)].reset_index(drop = True)\n",
    "        df_tournaments.to_sql('Tournaments', con=connection, index=False, if_exists='append')\n",
    "\n",
    "        df_maps=self.d_tables['Maps']\n",
    "        Maps_touse = df_maps['id'].unique()\n",
    "        df_maps.to_sql('Maps', con=connection, index=False, if_exists='append')  \n",
    "\n",
    "        df_matches = self.d_tables['Matches']\n",
    "        df_matches = df_matches[(df_matches['tournament_id'].isin(df_tournaments['id'].values)) &\\\n",
    "                                (df_matches['map_id'].isin(df_maps['id'].unique())) &\\\n",
    "                                (df_matches['winner_id'].isin(df_Teams['id'].unique()))].reset_index(drop = True) \n",
    "        df_matches.to_sql('Matches', con=connection, index=False, if_exists='append')\n",
    "\n",
    "        df_games = self.d_tables['Games']\n",
    "        df_games= df_games[(df_games['match_id'].isin(df_matches['id'])) &\\\n",
    "                           (df_games['team1_id'].isin(Teams_touse)) &\\\n",
    "                           (df_games['team2_id'].isin(Teams_touse))].reset_index(drop = True)\n",
    "        df_games.to_sql('Games', con=connection, index=False, if_exists='append')\n",
    "\n",
    "        df_rounds = self.d_tables['Rounds']\n",
    "        df_rounds = df_rounds[(df_rounds['ct_id'].isin(df_Teams['id'])) &\\\n",
    "                              (df_rounds['t_id'].isin(df_Teams['id'])) &\\\n",
    "                              (df_rounds['winner_team'].isin(df_Teams['id'])) &\\\n",
    "                              (df_rounds['game_id'].isin(df_games['id']))].reset_index(drop = True)\n",
    "        df_rounds.to_sql('Rounds', con=connection, index=False, if_exists='append')\n",
    "\n",
    "        df_stats= self.d_tables['Stats']\n",
    "        df_stats = df_stats[(df_stats['game_id'].isin(df_games['id']))&\\\n",
    "                             (df_stats['player_id'].isin(df_Players['id']))].reset_index(drop= True)\n",
    "        df_stats.to_sql('Stats', con=connection, index=False, if_exists='append')\n",
    "\n",
    "        df_Teams4Players = pd.concat([df_Teams['id'].to_frame('team_id'),\\\n",
    "                                      df_Players['id'].to_frame('player_id')],1)\n",
    "        df_Teams4Players.to_sql('Teams4Players', con=connection, index=False, if_exists='append')\n",
    "        \n",
    "        today = str(np.datetime64(datetime.today().date()))\n",
    "        print('Database was updated {} ...'.format(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LOG = r'C:\\Users\\Sergey\\Desktop\\logs\\log.txt'\n",
    "\n",
    "# Credentials to database connection\n",
    "hostname=\"localhost\"\n",
    "dbname=\"csgo_db\"\n",
    "uname=\"root\"\n",
    "pwd=\"serrg123456\"\n",
    "\n",
    "# Create SQLAlchemy engine to connect to MySQL Database\n",
    "CONNECTION = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\\\n",
    "                            .format(host=hostname, db=dbname, user=uname, pw=pwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "logtransformer = LogTransformerCSGO(PATH_TO_LOG, CONNECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb916a5bd3fc4d539e5633a23f4d45c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=602.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LogTransformerCSGO at 0x18022ea8580>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logtransformer.transform_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfdc5dceca149a98a9a80ba3b5f6ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=67.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d_tables = logtransformer.get_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database was updated 2021-07-30 ...\n"
     ]
    }
   ],
   "source": [
    "logtransformer.load_tables_to_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
